INFO 09-12 00:32:12 [__init__.py:241] Automatically detected platform cuda.
The image processor of type `Qwen2VLImageProcessor` is now loaded as a fast processor by default, even if the model checkpoint was saved with a slow processor. This is a breaking change and may produce slightly different outputs. To continue using the slow processor, instantiate this class with `use_fast=False`. Note that this behavior will be extended to all models in a future release.
MathVision Judge Evaluation Script
==================================================
Judge model: /home/minyingqian/models/Qwen2.5-VL-7B-Instruct
Input file: MathVision_inferenced.jsonl
Output file: MathVision_judge_results.jsonl
Tensor parallel size: 4
Batch size: 20
Has images: True
INFO 09-12 00:32:14 [utils.py:326] non-default args: {'model': '/home/minyingqian/models/Qwen2.5-VL-7B-Instruct', 'trust_remote_code': True, 'tensor_parallel_size': 4, 'disable_log_stats': True, 'limit_mm_per_prompt': {'image': 10, 'video': 2}}
The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
INFO 09-12 00:32:21 [__init__.py:711] Resolved architecture: Qwen2_5_VLForConditionalGeneration
`torch_dtype` is deprecated! Use `dtype` instead!
INFO 09-12 00:32:21 [__init__.py:1750] Using max model len 128000
INFO 09-12 00:32:21 [scheduler.py:222] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 09-12 00:32:28 [__init__.py:241] Automatically detected platform cuda.
[1;36m(EngineCore_0 pid=3019596)[0;0m INFO 09-12 00:32:29 [core.py:636] Waiting for init message from front-end.
[1;36m(EngineCore_0 pid=3019596)[0;0m INFO 09-12 00:32:29 [core.py:74] Initializing a V1 LLM engine (v0.10.1.1) with config: model='/home/minyingqian/models/Qwen2.5-VL-7B-Instruct', speculative_config=None, tokenizer='/home/minyingqian/models/Qwen2.5-VL-7B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=128000, download_dir=None, load_format=auto, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=/home/minyingqian/models/Qwen2.5-VL-7B-Instruct, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={"level":3,"debug_dump_path":"","cache_dir":"","backend":"","custom_ops":[],"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output","vllm.mamba_mixer2"],"use_inductor":true,"compile_sizes":[],"inductor_compile_config":{"enable_auto_functionalized_v2":false},"inductor_passes":{},"cudagraph_mode":1,"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"cudagraph_copy_inputs":false,"full_cuda_graph":false,"pass_config":{},"max_capture_size":512,"local_cache_dir":null}
[1;36m(EngineCore_0 pid=3019596)[0;0m WARNING 09-12 00:32:29 [multiproc_worker_utils.py:273] Reducing Torch parallelism from 48 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
[1;36m(EngineCore_0 pid=3019596)[0;0m INFO 09-12 00:32:29 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 16777216, 10, 'psm_948cf883'), local_subscribe_addr='ipc:///tmp/c01ea933-dd60-4b99-8b8b-c64207e4c58f', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 09-12 00:32:33 [__init__.py:241] Automatically detected platform cuda.
INFO 09-12 00:32:33 [__init__.py:241] Automatically detected platform cuda.
INFO 09-12 00:32:33 [__init__.py:241] Automatically detected platform cuda.
INFO 09-12 00:32:33 [__init__.py:241] Automatically detected platform cuda.
[1;36m(VllmWorker TP1 pid=3019752)[0;0m INFO 09-12 00:32:36 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_01ff60c2'), local_subscribe_addr='ipc:///tmp/2b2003c1-321a-4197-979c-ecf4a523748c', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker TP0 pid=3019751)[0;0m INFO 09-12 00:32:36 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_03ce9fac'), local_subscribe_addr='ipc:///tmp/964724e3-ed2c-47b2-9762-91893e3a8af4', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker TP3 pid=3019754)[0;0m INFO 09-12 00:32:36 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_e3da5dad'), local_subscribe_addr='ipc:///tmp/68d0a69c-0cb6-448d-9c88-5e8b02341ae4', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker TP2 pid=3019753)[0;0m INFO 09-12 00:32:36 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_25a78c02'), local_subscribe_addr='ipc:///tmp/0241e570-caa6-4335-affe-2b08dda19f3a', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker TP2 pid=3019753)[0;0m INFO 09-12 00:32:37 [__init__.py:1418] Found nccl from library libnccl.so.2
[1;36m(VllmWorker TP2 pid=3019753)[0;0m INFO 09-12 00:32:37 [pynccl.py:70] vLLM is using nccl==2.26.2
[1;36m(VllmWorker TP1 pid=3019752)[0;0m INFO 09-12 00:32:37 [__init__.py:1418] Found nccl from library libnccl.so.2
[1;36m(VllmWorker TP1 pid=3019752)[0;0m INFO 09-12 00:32:37 [pynccl.py:70] vLLM is using nccl==2.26.2
[1;36m(VllmWorker TP3 pid=3019754)[0;0m INFO 09-12 00:32:37 [__init__.py:1418] Found nccl from library libnccl.so.2
[1;36m(VllmWorker TP3 pid=3019754)[0;0m INFO 09-12 00:32:37 [pynccl.py:70] vLLM is using nccl==2.26.2
[1;36m(VllmWorker TP0 pid=3019751)[0;0m INFO 09-12 00:32:37 [__init__.py:1418] Found nccl from library libnccl.so.2
[1;36m(VllmWorker TP0 pid=3019751)[0;0m INFO 09-12 00:32:37 [pynccl.py:70] vLLM is using nccl==2.26.2
[1;36m(VllmWorker TP1 pid=3019752)[0;0m WARNING 09-12 00:32:38 [custom_all_reduce.py:137] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorker TP2 pid=3019753)[0;0m WARNING 09-12 00:32:38 [custom_all_reduce.py:137] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorker TP0 pid=3019751)[0;0m WARNING 09-12 00:32:38 [custom_all_reduce.py:137] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorker TP3 pid=3019754)[0;0m WARNING 09-12 00:32:38 [custom_all_reduce.py:137] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.
[1;36m(VllmWorker TP0 pid=3019751)[0;0m INFO 09-12 00:32:38 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_5b19f738'), local_subscribe_addr='ipc:///tmp/26b84e3b-7009-49a7-9032-b9ba2a15e1d6', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker TP3 pid=3019754)[0;0m INFO 09-12 00:32:38 [parallel_state.py:1134] rank 3 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 3, EP rank 3
[1;36m(VllmWorker TP0 pid=3019751)[0;0m INFO 09-12 00:32:38 [parallel_state.py:1134] rank 0 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(VllmWorker TP1 pid=3019752)[0;0m INFO 09-12 00:32:38 [parallel_state.py:1134] rank 1 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 1, EP rank 1
[1;36m(VllmWorker TP2 pid=3019753)[0;0m INFO 09-12 00:32:38 [parallel_state.py:1134] rank 2 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 2, EP rank 2
[1;36m(VllmWorker TP0 pid=3019751)[0;0m WARNING 09-12 00:32:38 [topk_topp_sampler.py:61] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
[1;36m(VllmWorker TP3 pid=3019754)[0;0m WARNING 09-12 00:32:38 [topk_topp_sampler.py:61] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
[1;36m(VllmWorker TP1 pid=3019752)[0;0m WARNING 09-12 00:32:38 [topk_topp_sampler.py:61] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
[1;36m(VllmWorker TP2 pid=3019753)[0;0m WARNING 09-12 00:32:38 [topk_topp_sampler.py:61] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
[1;36m(VllmWorker TP3 pid=3019754)[0;0m INFO 09-12 00:32:41 [gpu_model_runner.py:1953] Starting to load model /home/minyingqian/models/Qwen2.5-VL-7B-Instruct...
[1;36m(VllmWorker TP1 pid=3019752)[0;0m INFO 09-12 00:32:41 [gpu_model_runner.py:1953] Starting to load model /home/minyingqian/models/Qwen2.5-VL-7B-Instruct...
[1;36m(VllmWorker TP0 pid=3019751)[0;0m INFO 09-12 00:32:41 [gpu_model_runner.py:1953] Starting to load model /home/minyingqian/models/Qwen2.5-VL-7B-Instruct...
[1;36m(VllmWorker TP3 pid=3019754)[0;0m INFO 09-12 00:32:41 [gpu_model_runner.py:1985] Loading model from scratch...
[1;36m(VllmWorker TP0 pid=3019751)[0;0m INFO 09-12 00:32:41 [gpu_model_runner.py:1985] Loading model from scratch...
[1;36m(VllmWorker TP1 pid=3019752)[0;0m INFO 09-12 00:32:41 [gpu_model_runner.py:1985] Loading model from scratch...
[1;36m(VllmWorker TP3 pid=3019754)[0;0m INFO 09-12 00:32:41 [cuda.py:328] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker TP0 pid=3019751)[0;0m INFO 09-12 00:32:41 [cuda.py:328] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker TP1 pid=3019752)[0;0m INFO 09-12 00:32:41 [cuda.py:328] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker TP2 pid=3019753)[0;0m INFO 09-12 00:32:42 [gpu_model_runner.py:1953] Starting to load model /home/minyingqian/models/Qwen2.5-VL-7B-Instruct...
[1;36m(VllmWorker TP0 pid=3019751)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/5 [00:00<?, ?it/s]
[1;36m(VllmWorker TP0 pid=3019751)[0;0m Loading safetensors checkpoint shards:  20% Completed | 1/5 [00:00<00:02,  1.92it/s]
[1;36m(VllmWorker TP2 pid=3019753)[0;0m INFO 09-12 00:32:42 [gpu_model_runner.py:1985] Loading model from scratch...
[1;36m(VllmWorker TP2 pid=3019753)[0;0m INFO 09-12 00:32:42 [cuda.py:328] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker TP0 pid=3019751)[0;0m Loading safetensors checkpoint shards:  40% Completed | 2/5 [00:01<00:01,  1.63it/s]
[1;36m(VllmWorker TP0 pid=3019751)[0;0m Loading safetensors checkpoint shards:  60% Completed | 3/5 [00:01<00:01,  1.65it/s]
[1;36m(VllmWorker TP0 pid=3019751)[0;0m Loading safetensors checkpoint shards:  80% Completed | 4/5 [00:01<00:00,  2.30it/s]
[1;36m(VllmWorker TP0 pid=3019751)[0;0m Loading safetensors checkpoint shards: 100% Completed | 5/5 [00:02<00:00,  2.07it/s]
[1;36m(VllmWorker TP0 pid=3019751)[0;0m Loading safetensors checkpoint shards: 100% Completed | 5/5 [00:02<00:00,  1.97it/s]
[1;36m(VllmWorker TP0 pid=3019751)[0;0m 
[1;36m(VllmWorker TP0 pid=3019751)[0;0m INFO 09-12 00:32:44 [default_loader.py:262] Loading weights took 2.63 seconds
[1;36m(VllmWorker TP1 pid=3019752)[0;0m INFO 09-12 00:32:44 [default_loader.py:262] Loading weights took 2.62 seconds
[1;36m(VllmWorker TP3 pid=3019754)[0;0m INFO 09-12 00:32:45 [default_loader.py:262] Loading weights took 3.09 seconds
[1;36m(VllmWorker TP0 pid=3019751)[0;0m INFO 09-12 00:32:45 [gpu_model_runner.py:2007] Model loading took 3.9977 GiB and 2.875916 seconds
[1;36m(VllmWorker TP1 pid=3019752)[0;0m INFO 09-12 00:32:45 [gpu_model_runner.py:2007] Model loading took 3.9977 GiB and 2.878460 seconds
[1;36m(VllmWorker TP2 pid=3019753)[0;0m INFO 09-12 00:32:45 [default_loader.py:262] Loading weights took 2.59 seconds
[1;36m(VllmWorker TP3 pid=3019754)[0;0m INFO 09-12 00:32:45 [gpu_model_runner.py:2007] Model loading took 3.9977 GiB and 3.331924 seconds
[1;36m(VllmWorker TP2 pid=3019753)[0;0m INFO 09-12 00:32:45 [gpu_model_runner.py:2007] Model loading took 3.9977 GiB and 2.832571 seconds
[1;36m(VllmWorker TP2 pid=3019753)[0;0m INFO 09-12 00:32:46 [gpu_model_runner.py:2591] Encoder cache will be initialized with a budget of 98304 tokens, and profiled with 1 video items of the maximum feature size.
[1;36m(VllmWorker TP3 pid=3019754)[0;0m INFO 09-12 00:32:46 [gpu_model_runner.py:2591] Encoder cache will be initialized with a budget of 98304 tokens, and profiled with 1 video items of the maximum feature size.
[1;36m(VllmWorker TP0 pid=3019751)[0;0m INFO 09-12 00:32:46 [gpu_model_runner.py:2591] Encoder cache will be initialized with a budget of 98304 tokens, and profiled with 1 video items of the maximum feature size.
[1;36m(VllmWorker TP1 pid=3019752)[0;0m INFO 09-12 00:32:46 [gpu_model_runner.py:2591] Encoder cache will be initialized with a budget of 98304 tokens, and profiled with 1 video items of the maximum feature size.
[1;36m(VllmWorker TP0 pid=3019751)[0;0m INFO 09-12 00:33:11 [backends.py:548] Using cache directory: /home/minyingqian/.cache/vllm/torch_compile_cache/7a1a193d31/rank_0_0/backbone for vLLM's torch.compile
[1;36m(VllmWorker TP0 pid=3019751)[0;0m INFO 09-12 00:33:11 [backends.py:559] Dynamo bytecode transform time: 4.25 s
[1;36m(VllmWorker TP1 pid=3019752)[0;0m INFO 09-12 00:33:11 [backends.py:548] Using cache directory: /home/minyingqian/.cache/vllm/torch_compile_cache/7a1a193d31/rank_1_0/backbone for vLLM's torch.compile
[1;36m(VllmWorker TP1 pid=3019752)[0;0m INFO 09-12 00:33:11 [backends.py:559] Dynamo bytecode transform time: 4.37 s
[1;36m(VllmWorker TP2 pid=3019753)[0;0m INFO 09-12 00:33:11 [backends.py:548] Using cache directory: /home/minyingqian/.cache/vllm/torch_compile_cache/7a1a193d31/rank_2_0/backbone for vLLM's torch.compile
[1;36m(VllmWorker TP2 pid=3019753)[0;0m INFO 09-12 00:33:11 [backends.py:559] Dynamo bytecode transform time: 4.38 s
[1;36m(VllmWorker TP3 pid=3019754)[0;0m INFO 09-12 00:33:11 [backends.py:548] Using cache directory: /home/minyingqian/.cache/vllm/torch_compile_cache/7a1a193d31/rank_3_0/backbone for vLLM's torch.compile
[1;36m(VllmWorker TP3 pid=3019754)[0;0m INFO 09-12 00:33:11 [backends.py:559] Dynamo bytecode transform time: 4.39 s
[1;36m(VllmWorker TP0 pid=3019751)[0;0m INFO 09-12 00:33:14 [backends.py:161] Directly load the compiled graph(s) for dynamic shape from the cache, took 3.290 s
[1;36m(VllmWorker TP2 pid=3019753)[0;0m INFO 09-12 00:33:15 [backends.py:161] Directly load the compiled graph(s) for dynamic shape from the cache, took 3.353 s
[1;36m(VllmWorker TP1 pid=3019752)[0;0m INFO 09-12 00:33:15 [backends.py:161] Directly load the compiled graph(s) for dynamic shape from the cache, took 3.446 s
[1;36m(VllmWorker TP3 pid=3019754)[0;0m INFO 09-12 00:33:15 [backends.py:161] Directly load the compiled graph(s) for dynamic shape from the cache, took 3.693 s
[1;36m(VllmWorker TP0 pid=3019751)[0;0m INFO 09-12 00:33:16 [monitor.py:34] torch.compile takes 4.25 s in total
[1;36m(VllmWorker TP2 pid=3019753)[0;0m INFO 09-12 00:33:16 [monitor.py:34] torch.compile takes 4.38 s in total
[1;36m(VllmWorker TP1 pid=3019752)[0;0m INFO 09-12 00:33:16 [monitor.py:34] torch.compile takes 4.37 s in total
[1;36m(VllmWorker TP3 pid=3019754)[0;0m INFO 09-12 00:33:16 [monitor.py:34] torch.compile takes 4.39 s in total
[1;36m(VllmWorker TP0 pid=3019751)[0;0m INFO 09-12 00:33:20 [gpu_worker.py:276] Available KV cache memory: 15.49 GiB
[1;36m(VllmWorker TP1 pid=3019752)[0;0m INFO 09-12 00:33:20 [gpu_worker.py:276] Available KV cache memory: 15.49 GiB
[1;36m(VllmWorker TP2 pid=3019753)[0;0m INFO 09-12 00:33:20 [gpu_worker.py:276] Available KV cache memory: 15.49 GiB
[1;36m(VllmWorker TP3 pid=3019754)[0;0m INFO 09-12 00:33:20 [gpu_worker.py:276] Available KV cache memory: 15.49 GiB
[1;36m(EngineCore_0 pid=3019596)[0;0m INFO 09-12 00:33:20 [kv_cache_utils.py:849] GPU KV cache size: 1,159,856 tokens
[1;36m(EngineCore_0 pid=3019596)[0;0m INFO 09-12 00:33:20 [kv_cache_utils.py:853] Maximum concurrency for 128,000 tokens per request: 9.06x
[1;36m(EngineCore_0 pid=3019596)[0;0m INFO 09-12 00:33:20 [kv_cache_utils.py:849] GPU KV cache size: 1,159,856 tokens
[1;36m(EngineCore_0 pid=3019596)[0;0m INFO 09-12 00:33:20 [kv_cache_utils.py:853] Maximum concurrency for 128,000 tokens per request: 9.06x
[1;36m(EngineCore_0 pid=3019596)[0;0m INFO 09-12 00:33:20 [kv_cache_utils.py:849] GPU KV cache size: 1,159,856 tokens
[1;36m(EngineCore_0 pid=3019596)[0;0m INFO 09-12 00:33:20 [kv_cache_utils.py:853] Maximum concurrency for 128,000 tokens per request: 9.06x
[1;36m(EngineCore_0 pid=3019596)[0;0m INFO 09-12 00:33:20 [kv_cache_utils.py:849] GPU KV cache size: 1,159,856 tokens
[1;36m(EngineCore_0 pid=3019596)[0;0m INFO 09-12 00:33:20 [kv_cache_utils.py:853] Maximum concurrency for 128,000 tokens per request: 9.06x
[1;36m(VllmWorker TP0 pid=3019751)[0;0m Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/67 [00:00<?, ?it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   1%|▏         | 1/67 [00:00<00:15,  4.27it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   3%|▎         | 2/67 [00:00<00:14,  4.59it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   4%|▍         | 3/67 [00:00<00:13,  4.74it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   6%|▌         | 4/67 [00:00<00:12,  4.87it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   7%|▋         | 5/67 [00:01<00:12,  4.94it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   9%|▉         | 6/67 [00:01<00:12,  4.97it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  10%|█         | 7/67 [00:01<00:11,  5.04it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  12%|█▏        | 8/67 [00:01<00:11,  5.10it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  13%|█▎        | 9/67 [00:01<00:11,  5.16it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  15%|█▍        | 10/67 [00:01<00:10,  5.19it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  16%|█▋        | 11/67 [00:02<00:10,  5.26it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  18%|█▊        | 12/67 [00:02<00:10,  5.32it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  19%|█▉        | 13/67 [00:02<00:10,  5.36it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  21%|██        | 14/67 [00:02<00:09,  5.41it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  22%|██▏       | 15/67 [00:02<00:09,  5.48it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  24%|██▍       | 16/67 [00:03<00:09,  5.54it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|██▌       | 17/67 [00:03<00:08,  5.58it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  27%|██▋       | 18/67 [00:03<00:08,  5.65it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  28%|██▊       | 19/67 [00:03<00:08,  5.72it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  30%|██▉       | 20/67 [00:03<00:08,  5.78it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  31%|███▏      | 21/67 [00:03<00:07,  5.87it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|███▎      | 22/67 [00:04<00:07,  5.99it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  34%|███▍      | 23/67 [00:04<00:07,  6.04it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  36%|███▌      | 24/67 [00:04<00:07,  6.13it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|███▋      | 25/67 [00:04<00:06,  6.24it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  39%|███▉      | 26/67 [00:04<00:06,  6.42it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|████      | 27/67 [00:04<00:06,  6.42it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  42%|████▏     | 28/67 [00:05<00:05,  6.50it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|████▎     | 29/67 [00:05<00:05,  6.61it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  45%|████▍     | 30/67 [00:05<00:05,  6.77it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  46%|████▋     | 31/67 [00:05<00:05,  6.91it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  48%|████▊     | 32/67 [00:05<00:05,  6.90it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  49%|████▉     | 33/67 [00:05<00:04,  6.96it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  51%|█████     | 34/67 [00:05<00:04,  7.09it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  52%|█████▏    | 35/67 [00:05<00:04,  7.16it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  54%|█████▎    | 36/67 [00:06<00:04,  7.33it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  55%|█████▌    | 37/67 [00:06<00:03,  7.51it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|█████▋    | 38/67 [00:06<00:03,  7.67it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  58%|█████▊    | 39/67 [00:06<00:03,  7.79it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|█████▉    | 40/67 [00:06<00:03,  7.95it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  61%|██████    | 41/67 [00:06<00:03,  8.06it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|██████▎   | 42/67 [00:06<00:03,  8.17it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  64%|██████▍   | 43/67 [00:06<00:02,  8.37it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  66%|██████▌   | 44/67 [00:07<00:02,  8.60it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 45/67 [00:07<00:02,  8.73it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  69%|██████▊   | 46/67 [00:07<00:02,  8.88it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  70%|███████   | 47/67 [00:07<00:02,  9.06it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  72%|███████▏  | 48/67 [00:07<00:02,  8.75it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|███████▍  | 50/67 [00:07<00:01,  9.42it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  78%|███████▊  | 52/67 [00:07<00:01,  9.97it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  81%|████████  | 54/67 [00:08<00:01, 10.48it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  84%|████████▎ | 56/67 [00:08<00:00, 11.05it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  87%|████████▋ | 58/67 [00:08<00:00, 11.26it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  90%|████████▉ | 60/67 [00:08<00:00, 12.18it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  93%|█████████▎| 62/67 [00:08<00:00, 13.30it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  96%|█████████▌| 64/67 [00:08<00:00, 14.19it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  99%|█████████▊| 66/67 [00:08<00:00, 15.07it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 67/67 [00:08<00:00,  7.47it/s]
[1;36m(VllmWorker TP0 pid=3019751)[0;0m INFO 09-12 00:33:29 [gpu_model_runner.py:2708] Graph capturing finished in 9 secs, took 0.65 GiB
[1;36m(VllmWorker TP3 pid=3019754)[0;0m INFO 09-12 00:33:29 [gpu_model_runner.py:2708] Graph capturing finished in 9 secs, took 0.65 GiB
[1;36m(VllmWorker TP1 pid=3019752)[0;0m INFO 09-12 00:33:29 [gpu_model_runner.py:2708] Graph capturing finished in 9 secs, took 0.65 GiB
[1;36m(VllmWorker TP2 pid=3019753)[0;0m INFO 09-12 00:33:29 [gpu_model_runner.py:2708] Graph capturing finished in 9 secs, took 0.65 GiB
[1;36m(EngineCore_0 pid=3019596)[0;0m INFO 09-12 00:33:30 [core.py:214] init engine (profile, create kv cache, warmup model) took 44.11 seconds
INFO 09-12 00:33:35 [llm.py:298] Supported_tasks: ['generate']
Loading inference results from: MathVision_inferenced.jsonl
Loaded 303 inference results
Preparing judge inputs for 303 samples...
  0%|          | 0/303 [00:00<?, ?it/s]  1%|▏         | 4/303 [00:00<00:07, 38.91it/s]  5%|▍         | 15/303 [00:00<00:03, 72.83it/s]  8%|▊         | 23/303 [00:00<00:06, 45.20it/s] 10%|▉         | 30/303 [00:00<00:05, 51.76it/s] 12%|█▏        | 36/303 [00:00<00:05, 45.02it/s] 14%|█▍        | 42/303 [00:00<00:05, 48.39it/s] 17%|█▋        | 50/303 [00:00<00:04, 55.78it/s] 19%|█▉        | 57/303 [00:01<00:04, 49.94it/s] 22%|██▏       | 68/303 [00:01<00:03, 63.59it/s] 25%|██▍       | 75/303 [00:01<00:03, 62.62it/s] 33%|███▎      | 100/303 [00:01<00:01, 108.79it/s] 38%|███▊      | 114/303 [00:01<00:01, 116.56it/s] 43%|████▎     | 130/303 [00:01<00:01, 124.52it/s] 47%|████▋     | 143/303 [00:01<00:01, 115.12it/s] 52%|█████▏    | 158/303 [00:01<00:01, 120.50it/s] 56%|█████▋    | 171/303 [00:02<00:01, 109.01it/s] 60%|██████    | 183/303 [00:02<00:01, 94.97it/s]  66%|██████▋   | 201/303 [00:02<00:00, 113.39it/s] 71%|███████   | 214/303 [00:02<00:00, 100.65it/s] 76%|███████▌  | 229/303 [00:02<00:00, 106.21it/s] 81%|████████  | 246/303 [00:02<00:00, 119.79it/s] 85%|████████▌ | 259/303 [00:02<00:00, 119.81it/s] 90%|████████▉ | 272/303 [00:02<00:00, 119.66it/s] 94%|█████████▍| 285/303 [00:03<00:00, 113.44it/s] 98%|█████████▊| 297/303 [00:03<00:00, 101.45it/s]100%|██████████| 303/303 [00:03<00:00, 82.92it/s] 
Running judge evaluation...
Adding requests:   0%|          | 0/20 [00:00<?, ?it/s]Adding requests:   5%|▌         | 1/20 [00:02<00:56,  2.98s/it]Adding requests:  35%|███▌      | 7/20 [00:03<00:04,  3.06it/s]Adding requests:  75%|███████▌  | 15/20 [00:03<00:00,  7.70it/s]Adding requests: 100%|██████████| 20/20 [00:03<00:00,  5.87it/s]
Processed prompts:   0%|          | 0/20 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   5%|▌         | 1/20 [00:05<01:50,  5.80s/it, est. speed input: 68.22 toks/s, output: 0.34 toks/s]Processed prompts:  10%|█         | 2/20 [00:14<02:12,  7.38s/it, est. speed input: 83.63 toks/s, output: 0.28 toks/s]Processed prompts:  55%|█████▌    | 11/20 [00:16<00:09,  1.07s/it, est. speed input: 538.83 toks/s, output: 1.34 toks/s]Processed prompts: 100%|██████████| 20/20 [00:16<00:00,  1.07s/it, est. speed input: 1248.44 toks/s, output: 2.43 toks/s]Processed prompts: 100%|██████████| 20/20 [00:16<00:00,  1.22it/s, est. speed input: 1248.44 toks/s, output: 2.43 toks/s]
Adding requests:   0%|          | 0/20 [00:00<?, ?it/s]Adding requests:  15%|█▌        | 3/20 [00:00<00:00, 24.50it/s]Adding requests:  30%|███       | 6/20 [00:00<00:00, 23.60it/s]Adding requests:  55%|█████▌    | 11/20 [00:00<00:00, 25.61it/s]Adding requests:  70%|███████   | 14/20 [00:00<00:00, 21.24it/s]Adding requests:  90%|█████████ | 18/20 [00:00<00:00, 25.25it/s]Adding requests: 100%|██████████| 20/20 [00:00<00:00, 24.58it/s]
Processed prompts:   0%|          | 0/20 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   5%|▌         | 1/20 [00:07<02:26,  7.70s/it, est. speed input: 82.82 toks/s, output: 0.26 toks/s]Processed prompts:  10%|█         | 2/20 [00:16<02:29,  8.28s/it, est. speed input: 80.36 toks/s, output: 0.24 toks/s]Processed prompts:  30%|███       | 6/20 [00:22<00:42,  3.02s/it, est. speed input: 415.98 toks/s, output: 0.54 toks/s]Processed prompts:  60%|██████    | 12/20 [00:28<00:14,  1.76s/it, est. speed input: 704.75 toks/s, output: 0.85 toks/s]Processed prompts: 100%|██████████| 20/20 [00:28<00:00,  1.76s/it, est. speed input: 1137.80 toks/s, output: 1.42 toks/s]Processed prompts: 100%|██████████| 20/20 [00:28<00:00,  1.41s/it, est. speed input: 1137.80 toks/s, output: 1.42 toks/s]
Adding requests:   0%|          | 0/20 [00:00<?, ?it/s]Adding requests:  20%|██        | 4/20 [00:00<00:00, 38.27it/s]Adding requests:  50%|█████     | 10/20 [00:00<00:00, 42.17it/s]Adding requests:  75%|███████▌  | 15/20 [00:00<00:00, 32.44it/s]Adding requests: 100%|██████████| 20/20 [00:00<00:00, 37.88it/s]
Processed prompts:   0%|          | 0/20 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   5%|▌         | 1/20 [00:06<02:09,  6.79s/it, est. speed input: 145.36 toks/s, output: 0.29 toks/s]Processed prompts:  10%|█         | 2/20 [00:14<02:17,  7.62s/it, est. speed input: 158.63 toks/s, output: 0.27 toks/s]Processed prompts:  45%|████▌     | 9/20 [00:20<00:19,  1.80s/it, est. speed input: 451.62 toks/s, output: 0.87 toks/s]Processed prompts:  65%|██████▌   | 13/20 [00:20<00:07,  1.08s/it, est. speed input: 863.41 toks/s, output: 1.25 toks/s]Processed prompts: 100%|██████████| 20/20 [00:20<00:00,  1.85it/s, est. speed input: 1235.15 toks/s, output: 1.91 toks/s]Processed prompts: 100%|██████████| 20/20 [00:20<00:00,  1.85it/s, est. speed input: 1235.15 toks/s, output: 1.91 toks/s]Processed prompts: 100%|██████████| 20/20 [00:20<00:00,  1.05s/it, est. speed input: 1235.15 toks/s, output: 1.91 toks/s]
Adding requests:   0%|          | 0/20 [00:00<?, ?it/s]Adding requests:  25%|██▌       | 5/20 [00:00<00:00, 43.86it/s]Adding requests:  50%|█████     | 10/20 [00:00<00:00, 31.65it/s]Adding requests:  70%|███████   | 14/20 [00:00<00:00, 31.49it/s]Adding requests: 100%|██████████| 20/20 [00:00<00:00, 39.70it/s]
Processed prompts:   0%|          | 0/20 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   5%|▌         | 1/20 [00:07<02:15,  7.13s/it, est. speed input: 104.09 toks/s, output: 0.28 toks/s]Processed prompts:  10%|█         | 2/20 [00:14<02:11,  7.29s/it, est. speed input: 87.32 toks/s, output: 0.28 toks/s] Processed prompts:  40%|████      | 8/20 [00:17<00:20,  1.68s/it, est. speed input: 521.24 toks/s, output: 0.89 toks/s]Processed prompts: 100%|██████████| 20/20 [00:17<00:00,  1.68s/it, est. speed input: 1388.97 toks/s, output: 2.23 toks/s]Processed prompts: 100%|██████████| 20/20 [00:17<00:00,  1.11it/s, est. speed input: 1388.97 toks/s, output: 2.23 toks/s]
Adding requests:   0%|          | 0/20 [00:00<?, ?it/s]Adding requests:  45%|████▌     | 9/20 [00:00<00:00, 80.98it/s]Adding requests:  95%|█████████▌| 19/20 [00:00<00:00, 86.86it/s]Adding requests: 100%|██████████| 20/20 [00:00<00:00, 77.03it/s]
Processed prompts:   0%|          | 0/20 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   5%|▌         | 1/20 [00:03<01:14,  3.91s/it, est. speed input: 166.07 toks/s, output: 0.51 toks/s]Processed prompts:  10%|█         | 2/20 [00:07<01:11,  3.97s/it, est. speed input: 175.26 toks/s, output: 0.50 toks/s]Processed prompts:  45%|████▌     | 9/20 [00:10<00:09,  1.20it/s, est. speed input: 889.15 toks/s, output: 1.80 toks/s]Processed prompts: 100%|██████████| 20/20 [00:10<00:00,  1.20it/s, est. speed input: 2044.81 toks/s, output: 3.99 toks/s]Processed prompts: 100%|██████████| 20/20 [00:10<00:00,  1.99it/s, est. speed input: 2044.81 toks/s, output: 3.99 toks/s]
Adding requests:   0%|          | 0/20 [00:00<?, ?it/s]Adding requests:  25%|██▌       | 5/20 [00:00<00:00, 43.76it/s]Adding requests:  65%|██████▌   | 13/20 [00:00<00:00, 61.96it/s]Adding requests: 100%|██████████| 20/20 [00:00<00:00, 64.17it/s]Adding requests: 100%|██████████| 20/20 [00:00<00:00, 61.59it/s]
Processed prompts:   0%|          | 0/20 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   5%|▌         | 1/20 [00:04<01:30,  4.78s/it, est. speed input: 120.04 toks/s, output: 0.42 toks/s]Processed prompts:  10%|█         | 2/20 [00:09<01:26,  4.83s/it, est. speed input: 201.27 toks/s, output: 0.41 toks/s]Processed prompts:  40%|████      | 8/20 [00:12<00:14,  1.21s/it, est. speed input: 729.33 toks/s, output: 1.27 toks/s]Processed prompts: 100%|██████████| 20/20 [00:12<00:00,  1.21s/it, est. speed input: 1761.59 toks/s, output: 3.17 toks/s]Processed prompts: 100%|██████████| 20/20 [00:12<00:00,  1.59it/s, est. speed input: 1761.59 toks/s, output: 3.17 toks/s]
Adding requests:   0%|          | 0/20 [00:00<?, ?it/s]Adding requests:  35%|███▌      | 7/20 [00:00<00:00, 58.96it/s]Adding requests:  80%|████████  | 16/20 [00:00<00:00, 55.33it/s]Adding requests: 100%|██████████| 20/20 [00:00<00:00, 53.76it/s]
Processed prompts:   0%|          | 0/20 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   5%|▌         | 1/20 [00:04<01:26,  4.53s/it, est. speed input: 158.74 toks/s, output: 0.44 toks/s]Processed prompts:  10%|█         | 2/20 [00:10<01:38,  5.45s/it, est. speed input: 170.56 toks/s, output: 0.38 toks/s]Processed prompts:  40%|████      | 8/20 [00:14<00:17,  1.47s/it, est. speed input: 665.31 toks/s, output: 1.09 toks/s]Processed prompts: 100%|██████████| 20/20 [00:14<00:00,  1.47s/it, est. speed input: 1650.40 toks/s, output: 2.72 toks/s]Processed prompts: 100%|██████████| 20/20 [00:14<00:00,  1.36it/s, est. speed input: 1650.40 toks/s, output: 2.72 toks/s]
Adding requests:   0%|          | 0/20 [00:00<?, ?it/s]Adding requests:  20%|██        | 4/20 [00:00<00:00, 31.71it/s]Adding requests:  55%|█████▌    | 11/20 [00:00<00:00, 51.78it/s]Adding requests:  90%|█████████ | 18/20 [00:00<00:00, 58.39it/s]Adding requests: 100%|██████████| 20/20 [00:00<00:00, 56.60it/s]
Processed prompts:   0%|          | 0/20 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   5%|▌         | 1/20 [00:03<00:59,  3.14s/it, est. speed input: 266.76 toks/s, output: 0.64 toks/s]Processed prompts:  10%|█         | 2/20 [00:08<01:17,  4.29s/it, est. speed input: 257.54 toks/s, output: 0.49 toks/s]Processed prompts:  15%|█▌        | 3/20 [00:12<01:12,  4.29s/it, est. speed input: 960.92 toks/s, output: 0.48 toks/s]Processed prompts:  40%|████      | 8/20 [00:15<00:17,  1.50s/it, est. speed input: 1148.64 toks/s, output: 1.02 toks/s]Processed prompts: 100%|██████████| 20/20 [00:15<00:00,  1.50s/it, est. speed input: 1901.99 toks/s, output: 2.54 toks/s]Processed prompts: 100%|██████████| 20/20 [00:15<00:00,  1.27it/s, est. speed input: 1901.99 toks/s, output: 2.54 toks/s]
Adding requests:   0%|          | 0/20 [00:00<?, ?it/s]Adding requests:  20%|██        | 4/20 [00:00<00:00, 29.95it/s]Adding requests:  45%|████▌     | 9/20 [00:00<00:00, 38.33it/s]Adding requests:  80%|████████  | 16/20 [00:00<00:00, 44.37it/s]Adding requests: 100%|██████████| 20/20 [00:00<00:00, 43.42it/s]
Processed prompts:   0%|          | 0/20 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   5%|▌         | 1/20 [00:06<02:09,  6.82s/it, est. speed input: 83.12 toks/s, output: 0.29 toks/s]Processed prompts:  10%|█         | 2/20 [00:12<01:45,  5.87s/it, est. speed input: 206.78 toks/s, output: 0.33 toks/s]Processed prompts:  30%|███       | 6/20 [00:18<00:36,  2.62s/it, est. speed input: 474.41 toks/s, output: 0.64 toks/s]Processed prompts: 100%|██████████| 20/20 [00:18<00:00,  2.62s/it, est. speed input: 1325.71 toks/s, output: 2.15 toks/s]Processed prompts: 100%|██████████| 20/20 [00:18<00:00,  1.07it/s, est. speed input: 1325.71 toks/s, output: 2.15 toks/s]
Adding requests:   0%|          | 0/20 [00:00<?, ?it/s]Adding requests:  20%|██        | 4/20 [00:00<00:00, 36.98it/s]Adding requests:  40%|████      | 8/20 [00:00<00:00, 33.29it/s]Adding requests:  85%|████████▌ | 17/20 [00:00<00:00, 55.60it/s]Adding requests: 100%|██████████| 20/20 [00:00<00:00, 53.92it/s]
Processed prompts:   0%|          | 0/20 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   5%|▌         | 1/20 [00:06<02:09,  6.82s/it, est. speed input: 293.30 toks/s, output: 0.29 toks/s]Processed prompts:  10%|█         | 2/20 [00:09<01:23,  4.64s/it, est. speed input: 290.29 toks/s, output: 0.40 toks/s]Processed prompts:  40%|████      | 8/20 [00:13<00:15,  1.33s/it, est. speed input: 1274.99 toks/s, output: 1.14 toks/s]Processed prompts:  45%|████▌     | 9/20 [00:14<00:13,  1.27s/it, est. speed input: 1279.45 toks/s, output: 1.21 toks/s]Processed prompts: 100%|██████████| 20/20 [00:14<00:00,  1.27s/it, est. speed input: 1908.27 toks/s, output: 2.68 toks/s]Processed prompts: 100%|██████████| 20/20 [00:14<00:00,  1.34it/s, est. speed input: 1908.27 toks/s, output: 2.68 toks/s]
Adding requests:   0%|          | 0/20 [00:00<?, ?it/s]Adding requests:  15%|█▌        | 3/20 [00:00<00:00, 26.95it/s]Adding requests:  35%|███▌      | 7/20 [00:00<00:00, 18.40it/s]Adding requests:  60%|██████    | 12/20 [00:00<00:00, 27.63it/s]Adding requests:  95%|█████████▌| 19/20 [00:00<00:00, 39.58it/s]Adding requests: 100%|██████████| 20/20 [00:00<00:00, 34.29it/s]
Processed prompts:   0%|          | 0/20 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   5%|▌         | 1/20 [00:03<01:15,  3.99s/it, est. speed input: 236.62 toks/s, output: 0.50 toks/s]Processed prompts:  10%|█         | 2/20 [00:09<01:30,  5.00s/it, est. speed input: 269.87 toks/s, output: 0.41 toks/s]Processed prompts:  15%|█▌        | 3/20 [00:15<01:30,  5.30s/it, est. speed input: 745.13 toks/s, output: 0.39 toks/s]Processed prompts:  35%|███▌      | 7/20 [00:18<00:26,  2.07s/it, est. speed input: 933.04 toks/s, output: 0.75 toks/s]Processed prompts: 100%|██████████| 20/20 [00:18<00:00,  2.07s/it, est. speed input: 1653.64 toks/s, output: 2.14 toks/s]Processed prompts: 100%|██████████| 20/20 [00:18<00:00,  1.07it/s, est. speed input: 1653.64 toks/s, output: 2.14 toks/s]
Adding requests:   0%|          | 0/20 [00:00<?, ?it/s]Adding requests:  40%|████      | 8/20 [00:00<00:00, 75.75it/s]Adding requests:  80%|████████  | 16/20 [00:00<00:00, 43.19it/s]Adding requests: 100%|██████████| 20/20 [00:00<00:00, 50.24it/s]
Processed prompts:   0%|          | 0/20 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   5%|▌         | 1/20 [00:06<01:55,  6.08s/it, est. speed input: 160.09 toks/s, output: 0.33 toks/s]Processed prompts:  10%|█         | 2/20 [00:08<01:11,  4.00s/it, est. speed input: 185.22 toks/s, output: 0.46 toks/s]Processed prompts:  50%|█████     | 10/20 [00:16<00:13,  1.33s/it, est. speed input: 1229.36 toks/s, output: 1.24 toks/s]Processed prompts: 100%|██████████| 20/20 [00:16<00:00,  1.33s/it, est. speed input: 1842.64 toks/s, output: 2.48 toks/s]Processed prompts: 100%|██████████| 20/20 [00:16<00:00,  1.24it/s, est. speed input: 1842.64 toks/s, output: 2.48 toks/s]
Adding requests:   0%|          | 0/20 [00:00<?, ?it/s]Adding requests:  40%|████      | 8/20 [00:00<00:00, 76.25it/s]Adding requests:  80%|████████  | 16/20 [00:00<00:00, 52.27it/s]Adding requests: 100%|██████████| 20/20 [00:00<00:00, 60.22it/s]
Processed prompts:   0%|          | 0/20 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   5%|▌         | 1/20 [00:05<01:35,  5.01s/it, est. speed input: 146.41 toks/s, output: 0.40 toks/s]Processed prompts:  10%|█         | 2/20 [00:07<01:03,  3.55s/it, est. speed input: 183.91 toks/s, output: 0.53 toks/s]Processed prompts:  55%|█████▌    | 11/20 [00:15<00:10,  1.18s/it, est. speed input: 1193.10 toks/s, output: 1.43 toks/s]Processed prompts: 100%|██████████| 20/20 [00:15<00:00,  1.18s/it, est. speed input: 1871.23 toks/s, output: 2.60 toks/s]Processed prompts: 100%|██████████| 20/20 [00:15<00:00,  1.30it/s, est. speed input: 1871.23 toks/s, output: 2.60 toks/s]
Adding requests:   0%|          | 0/20 [00:00<?, ?it/s]Adding requests:  40%|████      | 8/20 [00:00<00:00, 56.77it/s]Adding requests:  70%|███████   | 14/20 [00:00<00:00, 53.76it/s]Adding requests: 100%|██████████| 20/20 [00:00<00:00, 47.48it/s]Adding requests: 100%|██████████| 20/20 [00:00<00:00, 49.43it/s]
Processed prompts:   0%|          | 0/20 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   5%|▌         | 1/20 [00:04<01:30,  4.76s/it, est. speed input: 170.81 toks/s, output: 0.42 toks/s]Processed prompts:  10%|█         | 2/20 [00:10<01:37,  5.40s/it, est. speed input: 147.81 toks/s, output: 0.38 toks/s]Processed prompts:  45%|████▌     | 9/20 [00:15<00:15,  1.39s/it, est. speed input: 619.29 toks/s, output: 1.16 toks/s]Processed prompts: 100%|██████████| 20/20 [00:15<00:00,  1.39s/it, est. speed input: 1621.20 toks/s, output: 2.57 toks/s]Processed prompts: 100%|██████████| 20/20 [00:15<00:00,  1.28it/s, est. speed input: 1621.20 toks/s, output: 2.57 toks/s]
Adding requests:   0%|          | 0/20 [00:00<?, ?it/s]Adding requests:  20%|██        | 4/20 [00:00<00:00, 39.12it/s]Adding requests:  40%|████      | 8/20 [00:00<00:00, 37.60it/s]Adding requests:  70%|███████   | 14/20 [00:00<00:00, 45.54it/s]Adding requests:  95%|█████████▌| 19/20 [00:00<00:00, 39.56it/s]Adding requests: 100%|██████████| 20/20 [00:00<00:00, 35.05it/s]
Processed prompts:   0%|          | 0/20 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   5%|▌         | 1/20 [00:06<02:09,  6.82s/it, est. speed input: 203.07 toks/s, output: 0.29 toks/s]Processed prompts:  10%|█         | 2/20 [00:12<01:48,  6.00s/it, est. speed input: 220.52 toks/s, output: 0.33 toks/s]Processed prompts:  35%|███▌      | 7/20 [00:20<00:32,  2.47s/it, est. speed input: 492.28 toks/s, output: 0.69 toks/s]Processed prompts:  70%|███████   | 14/20 [00:21<00:06,  1.01s/it, est. speed input: 847.79 toks/s, output: 1.32 toks/s]Processed prompts: 100%|██████████| 20/20 [00:21<00:00,  1.01s/it, est. speed input: 1336.91 toks/s, output: 1.89 toks/s]Processed prompts: 100%|██████████| 20/20 [00:21<00:00,  1.06s/it, est. speed input: 1336.91 toks/s, output: 1.89 toks/s]
Adding requests:   0%|          | 0/3 [00:00<?, ?it/s]Adding requests:  67%|██████▋   | 2/3 [00:00<00:00,  4.77it/s]Adding requests: 100%|██████████| 3/3 [00:00<00:00,  3.16it/s]Adding requests: 100%|██████████| 3/3 [00:00<00:00,  3.38it/s]
Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:  33%|███▎      | 1/3 [00:10<00:20, 10.09s/it, est. speed input: 134.55 toks/s, output: 0.20 toks/s]Processed prompts:  67%|██████▋   | 2/3 [00:21<00:10, 10.61s/it, est. speed input: 466.71 toks/s, output: 0.19 toks/s]Processed prompts: 100%|██████████| 3/3 [00:21<00:00, 10.61s/it, est. speed input: 926.14 toks/s, output: 0.28 toks/s]Processed prompts: 100%|██████████| 3/3 [00:21<00:00,  7.03s/it, est. speed input: 926.14 toks/s, output: 0.28 toks/s]
[1;36m(VllmWorker TP0 pid=3019751)[0;0m INFO 09-12 00:38:28 [multiproc_executor.py:520] Parent process exited, terminating worker
[1;36m(VllmWorker TP1 pid=3019752)[0;0m INFO 09-12 00:38:28 [multiproc_executor.py:520] Parent process exited, terminating worker
[1;36m(VllmWorker TP2 pid=3019753)[0;0m INFO 09-12 00:38:28 [multiproc_executor.py:520] Parent process exited, terminating worker
[1;36m(VllmWorker TP3 pid=3019754)[0;0m INFO 09-12 00:38:28 [multiproc_executor.py:520] Parent process exited, terminating worker
Saving judge results to: MathVision_judge_results.jsonl
Judge results saved to: MathVision_judge_results.jsonl

=== Judge Evaluation Results ===
Total samples: 303
Correct judgments: 88
Accuracy: 0.2904 (29.04%)
Metrics saved to: MathVision_judge_results_metrics.json
